{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train, dev, test split\n",
    "- train set = 3696 utterance (sa removed)\n",
    "- dev set = 50 speakers, 400 utterance\n",
    "- core test set = 24 speakers, 192 utterance\n",
    "\n",
    "## input preprocessing\n",
    "- featurewise zero mean unit variance scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from python_speech_features import mfcc, fbank, delta\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import scipy.io.wavfile as wav\n",
    "import subprocess\n",
    "import os, time, pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phn_61 = ['aa', 'ae', 'ah', 'ao', 'aw', 'ax', 'ax-h', 'axr', 'ay', 'b', 'bcl', 'ch', 'd', 'dcl', 'dh',\n",
    "          'dx', 'eh', 'el', 'em', 'en', 'eng', 'epi', 'er', 'ey', 'f', 'g', 'gcl', 'h#', 'hh', 'hv', \n",
    "          'ih', 'ix', 'iy', 'jh', 'k', 'kcl', 'l', 'm', 'n', 'ng', 'nx', 'ow', 'oy', 'p', 'pau', 'pcl',\n",
    "          'q', 'r', 's', 'sh', 't', 'tcl', 'th', 'uh', 'uw', 'ux', 'v', 'w', 'y', 'z', 'zh']\n",
    "\n",
    "mapping = {'ah': 'ax', 'ax-h': 'ax', 'ux': 'uw', 'aa': 'ao', 'ih': 'ix',\n",
    "               'axr': 'er', 'el': 'l', 'em': 'm', 'en': 'n', 'nx': 'n',\n",
    "               'eng': 'ng', 'sh': 'zh', 'hv': 'hh', 'bcl': 'h#', 'pcl': 'h#',\n",
    "               'dcl': 'h#', 'tcl': 'h#', 'gcl': 'h#', 'kcl': 'h#',\n",
    "               'q': 'h#', 'epi': 'h#', 'pau': 'h#'}\n",
    "\n",
    "phn_39 = ['ae', 'ao', 'aw', 'ax', 'ay', 'b', 'ch', 'd', 'dh', 'dx', 'eh', \n",
    "             'er', 'ey', 'f', 'g', 'h#', 'hh', 'ix', 'iy', 'jh', 'k', 'l', \n",
    "             'm', 'n', 'ng', 'ow', 'oy', 'p', 'r', 's', 't', 'th', 'uh', 'uw',\n",
    "             'v', 'w', 'y', 'z', 'zh']\n",
    "\n",
    "development_set = ['faks0', 'mmdb1', 'mbdg0', 'fedw0', 'mtdt0', 'fsem0', 'mdvc0', 'mrjm4', 'mjsw0', 'mteb0',\n",
    "                  'fdac1', 'mmdm2', 'mbwm0', 'mgjf0', 'mthc0', 'mbns0', 'mers0', 'fcal1', 'mreb0', 'mjfc0',\n",
    "                  'fjem0', 'mpdf0', 'mcsh0', 'mglb0', 'mwjg0', 'mmjr0', 'fmah0', 'mmwh0', 'fgjd0', 'mrjr0',\n",
    "                  'mgwt0', 'fcmh0', 'fadg0', 'mrtk0', 'fnmr0', 'mdls0', 'fdrw0', 'fjsj0', 'fjmg0', 'fmml0',\n",
    "                  'mjar0', 'fkms0', 'fdms0', 'mtaa0', 'frew0', 'mdlf0', 'mrcs0', 'majc0', 'mroa0', 'mrws1']\n",
    "\n",
    "core_test_set = ['mdab0', 'mwbt0', 'felc0', 'mtas1', 'mwew0', 'fpas0', 'mjmp0', 'mlnt0', 'fpkt0',\n",
    "             'mlll0', 'mtls0', 'fjlm0', 'mbpm0', 'mklt0', 'fnlp0', 'mcmj0', 'mjdh0', 'fmgd0',\n",
    "            'mgrt0', 'mnjm0', 'fdhc0', 'mjln0', 'mpam0', 'fmld0']\n",
    "\n",
    "\n",
    "TIMIT_DIR = './' # root directory for timit, it would be joined with timit/train or timit/test\n",
    "TFRECORD_DIR = './data' # directory for tfrecords files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_timit_dataset(train_set=True, dev_set=True, test_set=True, feats_type='mfcc'):\n",
    "    '''\n",
    "    feats_type:\n",
    "    - mfcc: 13 mel frequency cepstral coefficients + delta + delta delta, total 39 dimension\n",
    "    - fbank: 40 log filter bank with energy + delta + delta delta, total 123 dimension\n",
    "    '''\n",
    "    \n",
    "    def create_tfrecords(tfrecord_path, root_dir, fname, filter_fn):\n",
    "        writer = tf.python_io.TFRecordWriter(os.path.join(tfrecord_path, (fname + '.tfrecords')))\n",
    "        feats_list = []\n",
    "        phoneme_list = []\n",
    "        start = time.time()\n",
    "        cnt = 0\n",
    "        for path, dirs, files in os.walk(root_dir):\n",
    "            for file in files:\n",
    "                if filter_fn(file, path):\n",
    "                    continue\n",
    "                if file.endswith('wav'):\n",
    "                    fullFileName = os.path.join(path, file)\n",
    "                    fnameNoSuffix = os.path.splitext(fullFileName)[0]\n",
    "                    fNameTmp = fnameNoSuffix + '_tmp.wav'\n",
    "                    # convert nist file format to wav with command line program 'sox'\n",
    "                    subprocess.call(['sox', fullFileName, fNameTmp], shell=True)\n",
    "                    rate, sig = wav.read(fNameTmp)\n",
    "                    os.remove(fNameTmp)\n",
    "\n",
    "                    if feats_type == 'mfcc':\n",
    "                        mfcc_feat = mfcc(sig, rate)\n",
    "                        mfcc_feat_delta = delta(mfcc_feat, 2)\n",
    "                        mfcc_feat_delta_delta = delta(mfcc_feat_delta, 2)\n",
    "                        feats = np.concatenate((mfcc_feat, mfcc_feat_delta, mfcc_feat_delta_delta), axis=1)\n",
    "                    else: # fbank\n",
    "                        filters, energy = fbank(sig, rate, nfilt=40)\n",
    "                        log_filters, log_energy = np.log(filters), np.log(energy)\n",
    "                        logfbank_feat = np.concatenate((log_filters, log_energy.reshape(-1,1)), axis=1)\n",
    "                        logfbank_feat_delta = delta(logfbank_feat, 2)\n",
    "                        logfbank_feat_delta_delta = delta(logfbank_feat_delta, 2)\n",
    "                        feats = np.concatenate((logfbank_feat, logfbank_feat_delta, logfbank_feat_delta_delta), axis=1)\n",
    "                    feats_list.append(feats)\n",
    "\n",
    "                    # .phn\n",
    "                    phoneme = []\n",
    "                    with open(fnameNoSuffix + '.phn', 'r') as f:\n",
    "                        for line in f.read().splitlines():\n",
    "                            phn = line.split(' ')[2]\n",
    "                            p_index = phn_61.index(phn)\n",
    "                            phoneme.append(p_index)\n",
    "                    phoneme_list.append(phoneme)\n",
    "\n",
    "                    cnt += 1\n",
    "                    \n",
    "        if fname == 'train':\n",
    "            scaler = StandardScaler()\n",
    "            scaler.fit(np.concatenate(feats_list, axis=0))\n",
    "            print('scaler.n_samples_seen_:', scaler.n_samples_seen_)\n",
    "            pickle.dump(scaler, open(os.path.join(tfrecord_path, 'scaler.pkl'), 'wb'))\n",
    "            \n",
    "        if not os.path.exists(os.path.join(tfrecord_path, 'scaler.pkl')):\n",
    "            raise Exception('scaler.pkl not exist, call with [train_set=True]')\n",
    "        else:\n",
    "            scaler = pickle.load(open(os.path.join(tfrecord_path, 'scaler.pkl'), 'rb'))\n",
    "        \n",
    "        for feats, phoneme in zip(feats_list, phoneme_list):\n",
    "            seq_exam = tf.train.SequenceExample()\n",
    "            seq_exam.context.feature['feats_dim'].int64_list.value.append(feats.shape[1])\n",
    "            seq_exam.context.feature['feats_seq_len'].int64_list.value.append(feats.shape[0])\n",
    "            seq_exam.context.feature['labels_seq_len'].int64_list.value.append(len(phoneme))\n",
    "\n",
    "            feats = scaler.transform(feats)\n",
    "            for feat in feats:\n",
    "                seq_exam.feature_lists.feature_list['features'].feature.add().float_list.value[:] = feat\n",
    "            for p in phoneme:\n",
    "                seq_exam.feature_lists.feature_list['labels'].feature.add().int64_list.value.append(p)\n",
    "            writer.write(seq_exam.SerializeToString())\n",
    "\n",
    "        writer.close()\n",
    "        print('{} created: {} utterances - {:.0f}s'.format(fname+'.tfrecords', cnt, (time.time()-start)))\n",
    "    # end create_tfrecords() definition\n",
    "    \n",
    "    tfrecord_path = os.path.join(TFRECORD_DIR, feats_type)\n",
    "    if not os.path.isdir(tfrecord_path):\n",
    "        os.makedirs(tfrecord_path)\n",
    "    \n",
    "    if train_set:\n",
    "        create_tfrecords(tfrecord_path, os.path.join(TIMIT_DIR, 'timit/train'), 'train',\n",
    "                         lambda file, _: file.startswith('sa'))\n",
    "    if dev_set:\n",
    "        create_tfrecords(tfrecord_path, os.path.join(TIMIT_DIR, 'timit/test'), 'dev', \n",
    "                         lambda file, path: file.startswith('sa') or os.path.split(path)[1] not in development_set)\n",
    "    if test_set:\n",
    "        create_tfrecords(tfrecord_path, os.path.join(TIMIT_DIR, 'timit/test'), 'test', \n",
    "                         lambda file, path: file.startswith('sa') or os.path.split(path)[1] not in core_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scaler.n_samples_seen_: 1128519\n",
      "train.tfrecords created: 3696 utterances - 549s\n",
      "dev.tfrecords created: 400 utterances - 58s\n",
      "test.tfrecords created: 192 utterances - 28s\n"
     ]
    }
   ],
   "source": [
    "prepare_timit_dataset(feats_type='fbank')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
